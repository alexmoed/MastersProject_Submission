{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/alexmoed/Master_project_Sonata/blob/Eval/eval_v006.ipynb",
      "authorship_tag": "ABX9TyNxQfn10V+0UMoUZiNCFQJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmoed/MastersProject_Submission/blob/main/scripts/Inference_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If using colab mount drive first\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "n9GX8cbSuoZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " @brief Gaussian Splat Segmentation Pipeline for ScanNet classification\n",
        " Integration and organization of existing inference code assisted by Claude AI (Anthropic).\n",
        " Multiple prompts used for combining separate model inference workflows into\n",
        " unified pipeline, data flow coordination, and result merging logic# (abbreviated from extended conversation).\n",
        "\n",
        " Base models and inference code from:\n",
        " Pointcept Contributors (2023). Pointcept: A Codebase for Point Cloud Perception Research [online].\n",
        " [Accessed 2025]. Available from: \"https://github.com/Pointcept/Pointcept\".\n",
        " Original Author: Xiaoyang Wu (xiaoyang.wu.cs@gmail.com)"
      ],
      "metadata": {
        "id": "sUGBXJnzLZJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLS"
      ],
      "metadata": {
        "id": "KI7vU5-KBUh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy versions are a ongoing issue in this install it must be below 1.25 to work 1.24.and 1.24.3 are tested and work\n",
        "#Uninstall numpy first\n",
        "#Restart session!!\n",
        "!pip uninstall -y numpy\n",
        "!pip uninstall -y numpy  # Run twice\n",
        "\n",
        "# Find any installs of numpy left\n",
        "!find /usr/local/lib/python*/site-packages -name \"numpy*\" -type d\n",
        "\n",
        "# Delete ALL numpy folders\n",
        "!rm -rf /usr/local/lib/python*/site-packages/numpy*\n",
        "!rm -rf /usr/local/lib/python*/dist-packages/numpy*\n",
        "!rm -rf ~/.local/lib/python*/site-packages/numpy*\n",
        "\n",
        "# Clean pip cache too\n",
        "!pip cache purge\n",
        "\n",
        "\n",
        "!pip install numpy==1.24.0 --no-cache-dir\n",
        "\n",
        "# Make sure the versions are correct and reload if not it needs to be 1.24.0\n",
        "import numpy as np\n",
        "if np.__version__ != \"1.24.0\":\n",
        "   print(f\"Wrong version: {np.__version__} Please restart runtime and rerun\")\n",
        "\n",
        "\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(f\"Numpy location: {np.__file__}\")\n"
      ],
      "metadata": {
        "id": "EiJR_jKXstJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import universal dependencies that arent impacted by order\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import os\n",
        "import gc\n",
        "import json\n"
      ],
      "metadata": {
        "id": "TA6820kf-QIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a verison cuda install that after running once that it saves the download and caches the install for speed. Also handles torch installs\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "j8OAZS2nBX_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first batch of installs installing cuda and pytorch older versions: This will take 10+ minutes\n",
        "%cd /content/drive/MyDrive/Pointcept/Installs\n",
        "exec(open('/content/drive/MyDrive/Pointcept/Installs/setup_cuda_torch.py').read())\n"
      ],
      "metadata": {
        "id": "Q0qEd_fRE1fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pointops that is needed for Sonata decoder head. This you have to run twice\n",
        "\n",
        "%cd Pointcept/libs/pointops\n",
        "!pip install -v -e.\n",
        "%cd /content/drive/MyDrive/Pointcept\n"
      ],
      "metadata": {
        "id": "UB-Vs7X6zcDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #More installs and configs required\n",
        " %cd /content/drive/MyDrive/Pointcept/Installs\n",
        " exec(open('/content/drive/MyDrive/Pointcept/Installs/setup_build_env.py').read())"
      ],
      "metadata": {
        "id": "ihPYki8jV9Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load and impliment pointops patches and wrapper\n",
        "%cd /content/drive/MyDrive/Pointcept/Installs\n",
        "exec(open('/content/drive/MyDrive/Pointcept/Installs/fix_ballquery_wrapper.py').read())"
      ],
      "metadata": {
        "id": "pTYh7JZv2SE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Splat Segementation Pipeline"
      ],
      "metadata": {
        "id": "pRuqlMdPE9D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports needed just for this pipeline\n",
        "import pandas as pd\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from pointcept.models import build_model\n",
        "from pointcept.utils.config import Config\n",
        "from pointcept.datasets.transform import Compose\n",
        "from plyfile import PlyData, PlyElement"
      ],
      "metadata": {
        "id": "Nc8mq2xWGc7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config for pipeline"
      ],
      "metadata": {
        "id": "g0E1Sup-Ge5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Living room scene\n",
        "PLY_PATH = '/content/drive/MyDrive/Pointcept/data/splat/KitchenDiner_cleaned_v014_rotation.ply'\n",
        "#Kitchen scene\n",
        "#PLY_PATH = '/content/drive/MyDrive/Pointcept/data/splat/KitchenDiner_cleaned_v010_rotation_just_kitchen.ply'\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Pointcept/data/splat_scannet_with_normals/'\n",
        "SCENE_NAME = 'KitchenDiner_cleaned_v014_rotation'\n",
        "SCENE_PATH = os.path.join(OUTPUT_DIR, SCENE_NAME)\n",
        "\n",
        "# Instance segementation\n",
        "FIRST_PASS_CONFIG = '/content/drive/MyDrive/Pointcept/configs/scannet/insseg-pointgroup-v1m2-0-ptv3-base.py'\n",
        "FIRST_PASS_CHECKPOINT = '/content/drive/MyDrive/Pointcept/exp/scannet/insseg-pointgroup-sonata_3/model/epoch_1200.pth'\n",
        "FIRST_PASS_GRID_SIZE = 0.023\n",
        "\n",
        "# Semantic Segmentation second pass\n",
        "SONATA_CONFIG = '/content/drive/MyDrive/Pointcept/configs/sonata/semseg-sonata-v1m1-0c-scannet-ft-fast.py'\n",
        "SONATA_CHECKPOINT = '/content/drive/MyDrive/Pointcept/exp/sonata/semseg-sonata-v1m1-0c-scannet-ft-_full_scene_v003/model/epoch_800.pth'\n",
        "SECOND_PASS_CONFIG = FIRST_PASS_CONFIG\n",
        "SECOND_PASS_CHECKPOINT = FIRST_PASS_CHECKPOINT\n",
        "SECOND_PASS_GRID_SIZE = 0.021\n",
        "\n",
        "#Instance Scannet 200\n",
        "SCANNET200_CONFIG = '/content/drive/MyDrive/Pointcept/Pointcept/configs/scannet200/insseg-pointgroup-v1m2-0-ptv3-base_1_scannet_200_v001.py'\n",
        "SCANNET200_CHECKPOINT = '/content/drive/MyDrive/Pointcept/exp/scannet/insseg-pointgroup-sonata_config_200_1/model/epoch_800.pth'\n",
        "SCANNET200_GRID_SIZE = 0.015\n",
        "SCANNET200_CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "# Point cloud parameters\n",
        "MODEL_FILTER = 1290000 #number of points that are filtered down to for predictions\n",
        "VIZ_MAX_POINTS = 50000 #This just controls the number of points ploty visualizes not the actual point count\n",
        "CONFIDENCE_THRESHOLD = 0.6\n",
        "LOW_CONFIDENCE_THRESHOLD = 0.3\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = [\n",
        "    \"wall\", \"floor\", \"cabinet\", \"bed\", \"chair\", \"sofa\", \"table\", \"door\",\n",
        "    \"window\", \"bookshelf\", \"picture\", \"counter\", \"desk\", \"curtain\",\n",
        "    \"refrigerator\", \"shower curtain\", \"toilet\", \"sink\", \"bathtub\", \"otherfurniture\"\n",
        "]"
      ],
      "metadata": {
        "id": "SvAR6vmMGJyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the ply file to NPY file"
      ],
      "metadata": {
        "id": "ZIVqcyq0GqWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def step1_ply_to_numpy():\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 1: PLY TO NUMPY CONVERSION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check if there is files in the scene_path already change SCENE_NAME to do a new npy\n",
        "    coord_path = os.path.join(SCENE_PATH, 'coord.npy')\n",
        "    if os.path.exists(coord_path):\n",
        "        print(\"Numpy arrays already exist, loading...\")\n",
        "        coord = np.load(os.path.join(SCENE_PATH, 'coord.npy'))\n",
        "        color = np.load(os.path.join(SCENE_PATH, 'color.npy'))\n",
        "        normal = np.load(os.path.join(SCENE_PATH, 'normal.npy'))\n",
        "        print(f\"Loaded {len(coord):,} points\")\n",
        "        return coord, color, normal\n",
        "\n",
        "    #Create output directory if doesnt exist\n",
        "    os.makedirs(SCENE_PATH, exist_ok=True)\n",
        "\n",
        "    # Load unmodified PLY\n",
        "    print(\"Loading PLY file...\")\n",
        "    plydata = PlyData.read(PLY_PATH)\n",
        "    vertex_data = plydata['vertex']\n",
        "    total_points = len(vertex_data)\n",
        "    print(f\"Total points: {total_points:,}\")\n",
        "\n",
        "    #Extract coordinates\n",
        "    coords = np.vstack([vertex_data['x'], vertex_data['y'], vertex_data['z']]).T\n",
        "\n",
        "    #Extract normals\n",
        "    normals = np.vstack([vertex_data['nx'], vertex_data['ny'], vertex_data['nz']]).T\n",
        "\n",
        "    # Convert SH to RGB for visualization only\n",
        "    SH_C0 = 0.28209479177387814\n",
        "    sh_dc = np.vstack([vertex_data['f_dc_0'], vertex_data['f_dc_1'], vertex_data['f_dc_2']]).T\n",
        "    rgb_normalized = 0.5 + SH_C0 * sh_dc\n",
        "    color = (rgb_normalized.clip(0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize size and coordinates for model processing to a uniform size based on training data\n",
        "    centroid = coords.mean(axis=0)\n",
        "    coords_centered = coords - centroid\n",
        "    current_extent = coords_centered.max(axis=0) - coords_centered.min(axis=0)\n",
        "    scale_factor = 8.0 / current_extent.max()\n",
        "    coord = coords_centered * scale_factor\n",
        "\n",
        "\n",
        "    normal_mags = np.linalg.norm(normals, axis=1)\n",
        "    normal = normals / (normal_mags[:, np.newaxis] + 1e-8)\n",
        "\n",
        "    # Save out arrays that will be used until the last step\n",
        "    print(\"Saving numpy arrays...\")\n",
        "    np.save(os.path.join(SCENE_PATH, 'coord.npy'), coord.astype(np.float32))\n",
        "    np.save(os.path.join(SCENE_PATH, 'color.npy'), color.astype(np.uint8))\n",
        "    np.save(os.path.join(SCENE_PATH, 'normal.npy'), normal.astype(np.float32))\n",
        "\n",
        "    print(\"Step PLY to NPY complete\")\n",
        "    return coord, color, normal\n",
        "\n",
        "\n",
        "coord, color, normal = step1_ply_to_numpy()"
      ],
      "metadata": {
        "id": "kwIT4bQ2GMZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do instance segementation predictions on the full scene: Scannet 20\n"
      ],
      "metadata": {
        "id": "nQ0EFSTkHE_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "looking for furniture and objects"
      ],
      "metadata": {
        "id": "3cVHNswDM0Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def step2_first_pass(coord_full, color_full, normal_full):\n",
        "\n",
        "   print(\"\\n\" + \"=\"*60)\n",
        "   print(\"STEP 2: FIRST PASS INSTANCE SEGMENTATION\")\n",
        "   print(\"=\"*60)\n",
        "\n",
        "   print(f\"Processing {len(coord_full):,} points\")\n",
        "\n",
        "   #Fiter down point count that get sent to the model\n",
        "   if len(coord_full) > MODEL_FILTER:\n",
        "       print(f\"Filtering to {MODEL_FILTER:,} points for model...\")\n",
        "       model_indices = np.random.choice(len(coord_full), MODEL_FILTER, replace=False)\n",
        "       coord = coord_full[model_indices]\n",
        "       color = color_full[model_indices]\n",
        "       normal = normal_full[model_indices]\n",
        "   else:\n",
        "       coord = coord_full\n",
        "       color = color_full\n",
        "       normal = normal_full\n",
        "       model_indices = np.arange(len(coord_full))\n",
        "\n",
        "   #Load model\n",
        "   print(\"Loading PointGroup model...\")\n",
        "   cfg = Config.fromfile(FIRST_PASS_CONFIG)\n",
        "   model = build_model(cfg.model).cuda()\n",
        "   model.eval()\n",
        "\n",
        "   checkpoint = torch.load(FIRST_PASS_CHECKPOINT, map_location='cuda')\n",
        "   weight = OrderedDict()\n",
        "   for key, value in checkpoint[\"state_dict\"].items():\n",
        "       if key.startswith(\"module.\"):\n",
        "           key = key[7:]\n",
        "       weight[key] = value\n",
        "   model.load_state_dict(weight, strict=True)\n",
        "\n",
        "   #Load data into a dictionary\n",
        "   data_dict = {\n",
        "       'coord': coord.copy(),\n",
        "       'color': color.copy(),\n",
        "       'normal': normal.copy(),\n",
        "       'segment': np.zeros(coord.shape[0], dtype=np.int32),\n",
        "       'instance': np.full(coord.shape[0], -1, dtype=np.int32),\n",
        "   }\n",
        "\n",
        "   #Save transformations into a dictionary\n",
        "   transform_list = [\n",
        "       dict(type=\"CenterShift\", apply_z=True),\n",
        "       dict(type=\"Copy\", keys_dict={\n",
        "           \"coord\": \"origin_coord\",\n",
        "           \"segment\": \"origin_segment\",\n",
        "           \"instance\": \"origin_instance\",\n",
        "       }),\n",
        "       dict(type=\"GridSample\", grid_size=FIRST_PASS_GRID_SIZE, hash_type=\"fnv\",\n",
        "            mode=\"train\", return_grid_coord=True),\n",
        "       dict(type=\"CenterShift\", apply_z=False),\n",
        "       dict(type=\"NormalizeColor\"),\n",
        "       dict(type=\"InstanceParser\", segment_ignore_index=(-1, 0, 1), instance_ignore_index=-1),\n",
        "   ]\n",
        "\n",
        "   transform = Compose(transform_list)\n",
        "   data_dict = transform(data_dict)\n",
        "\n",
        "   # Converting to tensors\n",
        "   for key in data_dict.keys():\n",
        "       if isinstance(data_dict[key], np.ndarray):\n",
        "           if key in ['segment', 'instance', 'grid_coord', 'origin_segment', 'origin_instance']:\n",
        "               data_dict[key] = torch.from_numpy(data_dict[key]).long()\n",
        "           elif key == 'bbox':\n",
        "               data_dict[key] = torch.from_numpy(data_dict[key]).long()\n",
        "           else:\n",
        "               data_dict[key] = torch.from_numpy(data_dict[key]).float()\n",
        "\n",
        "   for key in data_dict.keys():\n",
        "       if isinstance(data_dict[key], torch.Tensor):\n",
        "           data_dict[key] = data_dict[key].cuda()\n",
        "\n",
        "   # Create features\n",
        "   if all(k in data_dict for k in [\"coord\", \"color\", \"normal\"]):\n",
        "       feat = torch.cat([data_dict[\"coord\"], data_dict[\"color\"], data_dict[\"normal\"]], dim=1)\n",
        "       data_dict[\"feat\"] = feat\n",
        "\n",
        "   #Add get the lenght of each batch and\n",
        "   if \"coord\" in data_dict:\n",
        "       data_dict[\"batch\"] = torch.zeros(len(data_dict[\"coord\"]), dtype=torch.long).cuda()\n",
        "       data_dict[\"offset\"] = torch.tensor([len(data_dict[\"coord\"])], dtype=torch.long).cuda()\n",
        "\n",
        "   if \"origin_coord\" in data_dict:\n",
        "       data_dict[\"origin_offset\"] = torch.tensor([len(data_dict[\"origin_coord\"])], dtype=torch.long).cuda()\n",
        "\n",
        "   # Run inference\n",
        "   print(\"Running inference...\")\n",
        "   with torch.no_grad():\n",
        "       output_dict = model(data_dict)\n",
        "\n",
        "   # Process outputs\n",
        "   pred_masks = output_dict['pred_masks']\n",
        "   pred_scores = output_dict['pred_scores']\n",
        "   pred_classes = output_dict['pred_classes']\n",
        "\n",
        "   print(f\"Found {len(pred_scores)} predicted instances\")\n",
        "   print(f\"High confidence (>{CONFIDENCE_THRESHOLD}): {(pred_scores > CONFIDENCE_THRESHOLD).sum()}\")\n",
        "\n",
        "   # Map back if needed\n",
        "   if \"origin_coord\" in data_dict and pointops is not None:\n",
        "       reverse, _ = pointops.knn_query(\n",
        "           1, data_dict[\"coord\"].float(), data_dict[\"offset\"].int(),\n",
        "           data_dict[\"origin_coord\"].float(), data_dict[\"origin_offset\"].int(),\n",
        "       )\n",
        "       reverse = reverse.cpu().flatten().long()\n",
        "       pred_masks = pred_masks[:, reverse]\n",
        "\n",
        "   #Converting to numpy\n",
        "   pred_masks = pred_masks.cpu().numpy()\n",
        "   pred_scores = pred_scores.cpu().numpy()\n",
        "   pred_classes = pred_classes.cpu().numpy()\n",
        "\n",
        "   # Create instance predictions\n",
        "   instance_preds_filtered = np.full(len(coord), -1, dtype=np.int32)\n",
        "   for i in range(len(pred_scores)):\n",
        "       if pred_scores[i] < CONFIDENCE_THRESHOLD:\n",
        "           continue\n",
        "       mask = pred_masks[i] > 0\n",
        "       instance_preds_filtered[mask] = i\n",
        "\n",
        "   #Then map the predictions back to the full point cloud\n",
        "   instance_preds_full = np.full(len(coord_full), -1, dtype=np.int32)\n",
        "   instance_preds_full[model_indices] = instance_preds_filtered\n",
        "\n",
        "   # Create class predictions\n",
        "   class_preds_full = np.full(len(coord_full), -1, dtype=np.int32)\n",
        "   for i in range(len(pred_scores)):\n",
        "       if pred_scores[i] < CONFIDENCE_THRESHOLD:\n",
        "           continue\n",
        "       mask_full = instance_preds_full == i\n",
        "       class_preds_full[mask_full] = pred_classes[i]\n",
        "\n",
        "   # Save\n",
        "   instance_metadata = {\n",
        "       'pred_scores': pred_scores,\n",
        "       'pred_classes': pred_classes,\n",
        "       'num_instances': len(pred_scores),\n",
        "       'high_confidence_instances': (pred_scores > CONFIDENCE_THRESHOLD).sum()\n",
        "   }\n",
        "   np.save(os.path.join(SCENE_PATH, 'instance_preds_full.npy'), instance_preds_full)\n",
        "   np.save(os.path.join(SCENE_PATH, 'class_preds_full.npy'), class_preds_full)\n",
        "   np.save(os.path.join(SCENE_PATH, 'instance_metadata.npy'), instance_metadata)\n",
        "\n",
        "   # Visualization\n",
        "   print(\"\\nVisualizing results...\")\n",
        "   instances_to_show = []\n",
        "   for i in range(len(pred_scores)):\n",
        "       if pred_scores[i] >= CONFIDENCE_THRESHOLD:\n",
        "           instances_to_show.append((i, pred_scores[i], pred_classes[i]))\n",
        "\n",
        "   print(f\"Showing {len(instances_to_show)} high confidence instances\")\n",
        "\n",
        "   # Prepare visualization data\n",
        "   viz_indices = []\n",
        "   for inst_id, score, class_id in instances_to_show:\n",
        "       mask = instance_preds_full == inst_id\n",
        "       indices = np.where(mask)[0]\n",
        "\n",
        "       # Sample if too many points\n",
        "       if len(indices) > VIZ_MAX_POINTS // len(instances_to_show):\n",
        "           indices = np.random.choice(indices, VIZ_MAX_POINTS // len(instances_to_show), replace=False)\n",
        "       viz_indices.extend(indices)\n",
        "\n",
        "   viz_indices = np.array(viz_indices)\n",
        "\n",
        "   if len(viz_indices) > 0:\n",
        "       # Create color map for instances\n",
        "       instance_colors = px.colors.qualitative.Plotly\n",
        "\n",
        "       traces = []\n",
        "       for idx, (inst_id, score, class_id) in enumerate(instances_to_show):\n",
        "           mask = instance_preds_full[viz_indices] == inst_id\n",
        "           if mask.sum() == 0:\n",
        "               continue\n",
        "\n",
        "           points_idx = viz_indices[mask]\n",
        "           class_name = CLASS_NAMES[class_id] if 0 <= class_id < len(CLASS_NAMES) else f\"class_{class_id}\"\n",
        "\n",
        "           trace = go.Scatter3d(\n",
        "               x=coord_full[points_idx, 0],\n",
        "               y=coord_full[points_idx, 1],\n",
        "               z=coord_full[points_idx, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(\n",
        "                   size=2,\n",
        "                   color=instance_colors[idx % len(instance_colors)],\n",
        "               ),\n",
        "               name=f\"{class_name} (ID:{inst_id}, Score:{score:.2f})\",\n",
        "               showlegend=True\n",
        "           )\n",
        "           traces.append(trace)\n",
        "\n",
        "       # Create figure\n",
        "       fig = go.Figure(data=traces)\n",
        "       fig.update_layout(\n",
        "           title=f\"First Pass Instance Segmentation Results<br>Showing {len(instances_to_show)} high confidence instances\",\n",
        "           scene=dict(\n",
        "               xaxis_title='X',\n",
        "               yaxis_title='Y',\n",
        "               zaxis_title='Z',\n",
        "               aspectmode='data'\n",
        "           ),\n",
        "           width=1200,\n",
        "           height=800\n",
        "       )\n",
        "       fig.show()\n",
        "\n",
        "   del model\n",
        "   torch.cuda.empty_cache()\n",
        "\n",
        "   print(\"Step 2 complete\")\n",
        "   return instance_preds_full, class_preds_full, pred_scores, pred_classes\n",
        "\n",
        "\n",
        "instance_preds_full, class_preds_full, pred_scores, pred_classes = step2_first_pass(coord, color, normal)"
      ],
      "metadata": {
        "id": "pAhcpD6aG7CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Segementation just for the floor and walls"
      ],
      "metadata": {
        "id": "_2YJD_jaNGq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the threshold to stop where the floor gets predicted so it does not happen on the ceiling should be automatic but can be adjusted"
      ],
      "metadata": {
        "id": "UtVxyagQNJt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#protects high confidence predictions from previous step\n",
        "\n",
        "# Floor height parameters - adjust these as needed\n",
        "FLOOR_HEIGHT_PERCENTILE = 15  # Use bottom 15% of points as reference for floor height adjust as needed\n",
        "FLOOR_HEIGHT_THRESHOLD = None  # Manual override - set a specific Z value if needed\n",
        "FLOOR_HEIGHT_MARGIN = 0.1  # Additional margin above the threshold (in meters)\n",
        "\n",
        "def step3_semantic_improved(coord, color, normal, class_preds_full, instance_preds_full, pred_scores):\n",
        "\n",
        "   print(f\"Running semantic segmentation on ALL points for better wall/floor detection\")\n",
        "\n",
        "\n",
        "   # Calculate floor height threshold\n",
        "   z_coords = coord[:, 2]\n",
        "   if FLOOR_HEIGHT_THRESHOLD is None:\n",
        "       # Use percentile method\n",
        "       floor_height_limit = np.percentile(z_coords, FLOOR_HEIGHT_PERCENTILE) + FLOOR_HEIGHT_MARGIN\n",
        "       print(f\"\\nUsing automatic floor height limit: {floor_height_limit:.2f}m\")\n",
        "       print(f\"  (Based on {FLOOR_HEIGHT_PERCENTILE}th percentile + {FLOOR_HEIGHT_MARGIN}m margin)\")\n",
        "   else:\n",
        "       floor_height_limit = FLOOR_HEIGHT_THRESHOLD + FLOOR_HEIGHT_MARGIN\n",
        "       print(f\"\\nUsing manual floor height limit: {floor_height_limit:.2f}m\")\n",
        "\n",
        "\n",
        "   # Load model\n",
        "   print(\"\\nLoading SONATA model...\")\n",
        "   cfg = Config.fromfile(SONATA_CONFIG)\n",
        "   model = build_model(cfg.model).cuda()\n",
        "   model.eval()\n",
        "\n",
        "   checkpoint = torch.load(SONATA_CHECKPOINT, map_location='cuda')\n",
        "   weight = OrderedDict()\n",
        "   for key, value in checkpoint[\"state_dict\"].items():\n",
        "       if key.startswith(\"module.\"):\n",
        "           key = key[7:]\n",
        "       weight[key] = value\n",
        "   model.load_state_dict(weight, strict=True)\n",
        "\n",
        "\n",
        "   # Prepare data for ALL points\n",
        "   data_dict = {\n",
        "       'coord': coord.copy(),\n",
        "       'color': color.copy(),\n",
        "       'normal': normal.copy(),\n",
        "       'segment': np.zeros(coord.shape[0], dtype=np.int32),\n",
        "   }\n",
        "\n",
        "   # Apply transforms\n",
        "   transform = Compose(cfg.data.val.transform)\n",
        "   data_dict = transform(data_dict)\n",
        "\n",
        "   # Convert to tensors\n",
        "   for key in data_dict.keys():\n",
        "       if isinstance(data_dict[key], np.ndarray):\n",
        "           data_dict[key] = torch.from_numpy(data_dict[key])\n",
        "       if isinstance(data_dict[key], torch.Tensor):\n",
        "           data_dict[key] = data_dict[key].cuda()\n",
        "\n",
        "   data_dict['batch'] = torch.zeros(data_dict['coord'].shape[0], dtype=torch.long).cuda()\n",
        "   data_dict['offset'] = torch.tensor([data_dict['coord'].shape[0]], dtype=torch.long).cuda()\n",
        "\n",
        "\n",
        "   #Run inference on ALL points in the cloud\n",
        "   print(\"Running semantic segmentation on full cloud...\")\n",
        "   with torch.no_grad():\n",
        "       output = model(data_dict)\n",
        "       if hasattr(output, 'seg_logits'):\n",
        "           predictions = output.seg_logits.argmax(dim=-1)\n",
        "       else:\n",
        "           predictions = output['seg_logits'].argmax(dim=-1)\n",
        "\n",
        "   # Handle inverse mapping\n",
        "   if 'inverse' in data_dict:\n",
        "       inverse = data_dict['inverse'].cpu()\n",
        "       semantic_preds = predictions[inverse].cpu().numpy()\n",
        "   else:\n",
        "       semantic_preds = predictions.cpu().numpy()\n",
        "\n",
        "   print(f\"Got semantic predictions for all {len(semantic_preds)} points\")\n",
        "\n",
        "   # Analyze what semantic segmentation found\n",
        "   print(\"\\nSemantic classes found:\")\n",
        "   unique_classes, counts = np.unique(semantic_preds, return_counts=True)\n",
        "   for cls, count in zip(unique_classes, counts):\n",
        "       percentage = count / len(semantic_preds) * 100\n",
        "       class_name = CLASS_NAMES[cls] if 0 <= cls < len(CLASS_NAMES) else f\"class_{cls}\"\n",
        "       print(f\"  {class_name}: {count:,} points ({percentage:.1f}%)\")\n",
        "\n",
        "\n",
        "   print(f\"\\nMerging with step 1 results using priority system...\")\n",
        "\n",
        "   # Start with step 1 results\n",
        "   updated_class_preds = class_preds_full.copy()\n",
        "   wall_floor_attribute = np.zeros(len(coord), dtype=np.uint8)\n",
        "\n",
        "   # High confidence step 1 instances (protect these)\n",
        "   high_conf_mask = np.zeros(len(coord), dtype=bool)\n",
        "   if len(pred_scores) > 0:\n",
        "       for i in range(len(pred_scores)):\n",
        "           if pred_scores[i] >= CONFIDENCE_THRESHOLD:\n",
        "               high_conf_mask |= (instance_preds_full == i)\n",
        "\n",
        "   #Apply semantic results with priority rules\n",
        "   walls_from_semantic = 0\n",
        "   floors_from_semantic = 0\n",
        "   walls_override = 0\n",
        "   floors_override = 0\n",
        "   floors_rejected_height = 0\n",
        "\n",
        "   for i in range(len(coord)):\n",
        "       semantic_class = semantic_preds[i]\n",
        "       step1_class = class_preds_full[i]\n",
        "       is_high_conf = high_conf_mask[i]\n",
        "       point_height = z_coords[i]\n",
        "\n",
        "       # Keep high-confidence step 1 object classifications\n",
        "       if is_high_conf and step1_class >= 2:  # Objects from high-conf instances\n",
        "           # Keep step 1 classification\n",
        "           continue\n",
        "\n",
        "       #Use semantic walls/floors everywhere else\n",
        "       elif semantic_class == 0:  # Wall\n",
        "           if step1_class == -1:  # Was unclassified\n",
        "               walls_from_semantic += 1\n",
        "           elif step1_class >= 2:  # Override low-conf object\n",
        "               walls_override += 1\n",
        "           updated_class_preds[i] = 0\n",
        "           wall_floor_attribute[i] = 1\n",
        "\n",
        "       elif semantic_class == 1:  # Floor\n",
        "           # Apply height limit check\n",
        "           if point_height > floor_height_limit:\n",
        "               floors_rejected_height += 1\n",
        "           else:\n",
        "               if step1_class == -1:  # Was unclassified\n",
        "                   floors_from_semantic += 1\n",
        "               elif step1_class >= 2:  # Override low-conf object\n",
        "                   floors_override += 1\n",
        "               updated_class_preds[i] = 1\n",
        "               wall_floor_attribute[i] = 1\n",
        "\n",
        "       # RULE 3: For other semantic classes, only fill unclassified\n",
        "       elif step1_class == -1:\n",
        "           updated_class_preds[i] = semantic_class\n",
        "\n",
        "   # Show the improvement\n",
        "   unclassified_before = (class_preds_full == -1).sum()\n",
        "   unclassified_after = (updated_class_preds == -1).sum()\n",
        "   print(f\"  Unclassified points: {unclassified_before:,} â†’ {unclassified_after:,}\")\n",
        "\n",
        "   # Save results\n",
        "   np.save(os.path.join(SCENE_PATH, 'semantic_preds_full.npy'), semantic_preds)\n",
        "   np.save(os.path.join(SCENE_PATH, 'wall_floor_attribute.npy'), wall_floor_attribute)\n",
        "   np.save(os.path.join(SCENE_PATH, 'class_preds_updated.npy'), updated_class_preds)\n",
        "\n",
        "\n",
        "\n",
        "   # VISUALIZATION - Show the improvements\n",
        "   print(\"\\nVisualizing semantic improvements...\")\n",
        "\n",
        "   # Sample points for visualization\n",
        "   viz_sample = min(VIZ_MAX_POINTS, len(coord))\n",
        "   if len(coord) > viz_sample:\n",
        "       viz_indices = np.random.choice(len(coord), viz_sample, replace=False)\n",
        "   else:\n",
        "       viz_indices = np.arange(len(coord))\n",
        "\n",
        "   fig = go.Figure()\n",
        "\n",
        "   # Walls after merging\n",
        "   after_walls = (updated_class_preds == 0) & np.isin(np.arange(len(coord)), viz_indices)\n",
        "   wall_points_after = np.where(after_walls)[0]\n",
        "   if len(wall_points_after) > 0:\n",
        "       fig.add_trace(\n",
        "           go.Scatter3d(\n",
        "               x=coord[wall_points_after, 0],\n",
        "               y=coord[wall_points_after, 1],\n",
        "               z=coord[wall_points_after, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(size=2, color='blue', opacity=0.8),\n",
        "               name=f'Walls ({(updated_class_preds == 0).sum():,})',\n",
        "               showlegend=True\n",
        "           )\n",
        "       )\n",
        "\n",
        "   #Floors after merging versions\n",
        "   after_floors = (updated_class_preds == 1) & np.isin(np.arange(len(coord)), viz_indices)\n",
        "   floor_points_after = np.where(after_floors)[0]\n",
        "   if len(floor_points_after) > 0:\n",
        "       fig.add_trace(\n",
        "           go.Scatter3d(\n",
        "               x=coord[floor_points_after, 0],\n",
        "               y=coord[floor_points_after, 1],\n",
        "               z=coord[floor_points_after, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(size=2, color='green', opacity=0.8),\n",
        "               name=f'Floors ({(updated_class_preds == 1).sum():,})',\n",
        "               showlegend=True\n",
        "           )\n",
        "       )\n",
        "\n",
        "   # Protected high-confidence predicted objects from previous step\n",
        "   protected_objects = high_conf_mask & (updated_class_preds >= 2) & np.isin(np.arange(len(coord)), viz_indices)\n",
        "   object_points = np.where(protected_objects)[0]\n",
        "   if len(object_points) > 2000:  # Sample if too many\n",
        "       object_points = np.random.choice(object_points, 2000, replace=False)\n",
        "   if len(object_points) > 0:\n",
        "       fig.add_trace(\n",
        "           go.Scatter3d(\n",
        "               x=coord[object_points, 0],\n",
        "               y=coord[object_points, 1],\n",
        "               z=coord[object_points, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(size=2, color='orange', opacity=0.6),\n",
        "               name='Protected Objects',\n",
        "               showlegend=True\n",
        "           )\n",
        "       )\n",
        "\n",
        "   # Add floor height limit plane for reference\n",
        "   x_range = [coord[viz_indices, 0].min(), coord[viz_indices, 0].max()]\n",
        "   y_range = [coord[viz_indices, 1].min(), coord[viz_indices, 1].max()]\n",
        "\n",
        "   # Create a grid for the height limit plane\n",
        "   xx, yy = np.meshgrid(\n",
        "       np.linspace(x_range[0], x_range[1], 10),\n",
        "       np.linspace(y_range[0], y_range[1], 10)\n",
        "   )\n",
        "   zz = np.full_like(xx, floor_height_limit)\n",
        "\n",
        "   fig.add_trace(\n",
        "       go.Surface(\n",
        "           x=xx, y=yy, z=zz,\n",
        "           opacity=0.2,\n",
        "           colorscale=[[0, 'red'], [1, 'red']],\n",
        "           showscale=False,\n",
        "           name='Floor Height Limit'\n",
        "       )\n",
        "   )\n",
        "\n",
        "   fig.update_layout(\n",
        "       title=f\"Semantic Segmentation Results with Height Limit<br>\"\n",
        "             f\"Walls: {(updated_class_preds == 0).sum():,} | \"\n",
        "             f\"Floors: {(updated_class_preds == 1).sum():,} | \"\n",
        "             f\"Height Limit: Z={floor_height_limit:.2f}m\",\n",
        "       scene=dict(\n",
        "           xaxis_title='X',\n",
        "           yaxis_title='Y',\n",
        "           zaxis_title='Z',\n",
        "           aspectmode='data'\n",
        "       ),\n",
        "       showlegend=True,\n",
        "       height=800,\n",
        "       width=1200\n",
        "   )\n",
        "\n",
        "   fig.show()\n",
        "\n",
        "   #Clear up gpu memory\n",
        "   del model\n",
        "   torch.cuda.empty_cache()\n",
        "\n",
        "   print(\"Step 3 improved complete\")\n",
        "   return semantic_preds, wall_floor_attribute, updated_class_preds\n",
        "\n",
        "semantic_preds, wall_floor_attribute, class_preds_updated = step3_semantic_improved(\n",
        "   coord, color, normal, class_preds_full, instance_preds_full, pred_scores)"
      ],
      "metadata": {
        "id": "38sZXUYeM_n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#    Display the combined results from steps 2 and 3.\n"
      ],
      "metadata": {
        "id": "pFww0V1dNttS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def display_combined_results(coord, instance_preds_full, class_preds_updated):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMBINED RESULTS FROM STEPS 2-3\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get statistics\n",
        "    total_points = len(coord)\n",
        "    classified_points = (class_preds_updated >= 0).sum()\n",
        "    unclassified_points = (class_preds_updated == -1).sum()\n",
        "\n",
        "    print(f\"Total points: {total_points:,}\")\n",
        "    print(f\"Classified points: {classified_points:,} ({classified_points/total_points*100:.1f}%)\")\n",
        "    print(f\"Unclassified points: {unclassified_points:,} ({unclassified_points/total_points*100:.1f}%)\")\n",
        "\n",
        "    # Count by category\n",
        "    wall_count = (class_preds_updated == 0).sum()\n",
        "    floor_count = (class_preds_updated == 1).sum()\n",
        "    object_count = (class_preds_updated >= 2).sum()\n",
        "\n",
        "    print(f\"\\nPoint distribution:\")\n",
        "    print(f\"  Walls: {wall_count:,} points\")\n",
        "    print(f\"  Floors: {floor_count:,} points\")\n",
        "    print(f\"  Objects (ScanNet 20): {object_count:,} points\")\n",
        "\n",
        "    #Get unique instances\n",
        "    unique_instances = np.unique(instance_preds_full[instance_preds_full >= 0])\n",
        "    print(f\"\\nTotal instances: {len(unique_instances)}\")\n",
        "\n",
        "    traces = []\n",
        "\n",
        "    # Sample for visualization\n",
        "    viz_sample = min(VIZ_MAX_POINTS * 2, total_points)\n",
        "    if total_points > viz_sample:\n",
        "        sample_indices = np.random.choice(total_points, viz_sample, replace=False)\n",
        "    else:\n",
        "        sample_indices = np.arange(total_points)\n",
        "\n",
        "    #Walls\n",
        "    wall_mask = (class_preds_updated == 0) & np.isin(np.arange(total_points), sample_indices)\n",
        "    wall_points = np.where(wall_mask)[0]\n",
        "    if len(wall_points) > 0:\n",
        "        traces.append(go.Scatter3d(\n",
        "            x=coord[wall_points, 0],\n",
        "            y=coord[wall_points, 1],\n",
        "            z=coord[wall_points, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='lightblue', opacity=0.6),\n",
        "            name=f\"Walls ({wall_count:,} pts)\",\n",
        "            showlegend=True\n",
        "        ))\n",
        "\n",
        "    #Floors\n",
        "    floor_mask = (class_preds_updated == 1) & np.isin(np.arange(total_points), sample_indices)\n",
        "    floor_points = np.where(floor_mask)[0]\n",
        "    if len(floor_points) > 0:\n",
        "        traces.append(go.Scatter3d(\n",
        "            x=coord[floor_points, 0],\n",
        "            y=coord[floor_points, 1],\n",
        "            z=coord[floor_points, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='lightgreen', opacity=0.6),\n",
        "            name=f\"Floors ({floor_count:,} pts)\",\n",
        "            showlegend=True\n",
        "        ))\n",
        "\n",
        "    #Saved Objects from ScanNet 20\n",
        "    object_instances = []\n",
        "    for inst_id in unique_instances:\n",
        "        mask = instance_preds_full == inst_id\n",
        "        if mask.sum() > 0:\n",
        "            class_id = class_preds_updated[mask][0]\n",
        "            if class_id >= 2:  # Not wall or floor\n",
        "                object_instances.append((inst_id, class_id, mask.sum()))\n",
        "\n",
        "    #Sort by size\n",
        "    object_instances.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    #Color palette\n",
        "    instance_colors = px.colors.qualitative.Plotly * 5\n",
        "\n",
        "    print(f\"\\nShowing {len(object_instances)} object instances\")\n",
        "\n",
        "    for idx, (inst_id, class_id, size) in enumerate(object_instances[:30]):  # Show up to 30\n",
        "        mask = (instance_preds_full == inst_id) & np.isin(np.arange(total_points), sample_indices)\n",
        "        indices = np.where(mask)[0]\n",
        "\n",
        "        if len(indices) > 0:\n",
        "            class_name = CLASS_NAMES[class_id] if 0 <= class_id < len(CLASS_NAMES) else f\"class_{class_id}\"\n",
        "\n",
        "            traces.append(go.Scatter3d(\n",
        "                x=coord[indices, 0],\n",
        "                y=coord[indices, 1],\n",
        "                z=coord[indices, 2],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=2,\n",
        "                    color=instance_colors[idx % len(instance_colors)],\n",
        "                    opacity=0.9\n",
        "                ),\n",
        "                name=f\"{class_name} #{inst_id} ({size:,} pts)\",\n",
        "                showlegend=True\n",
        "            ))\n",
        "\n",
        "    #Unclassified points\n",
        "    unclass_mask = (class_preds_updated == -1) & np.isin(np.arange(total_points), sample_indices)\n",
        "    unclass_points = np.where(unclass_mask)[0]\n",
        "    if len(unclass_points) > 0:\n",
        "        traces.append(go.Scatter3d(\n",
        "            x=coord[unclass_points, 0],\n",
        "            y=coord[unclass_points, 1],\n",
        "            z=coord[unclass_points, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='gray', opacity=0.3),\n",
        "            name=f\"Unclassified ({unclassified_points:,} pts)\",\n",
        "            showlegend=True\n",
        "        ))\n",
        "\n",
        "    #Create the figure in ploty\n",
        "    fig = go.Figure(data=traces)\n",
        "    fig.update_layout(\n",
        "        title=f\"Combined Results: Steps 2-3 (ScanNet 20 + Walls/Floors)\",\n",
        "        scene=dict(\n",
        "            xaxis_title='X',\n",
        "            yaxis_title='Y',\n",
        "            zaxis_title='Z',\n",
        "            aspectmode='data'\n",
        "        ),\n",
        "        width=1400,\n",
        "        height=900,\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.99,\n",
        "            xanchor=\"right\",\n",
        "            x=0.99,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "            font=dict(size=10)\n",
        "        )\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    print(\"\\nClass distribution:\")\n",
        "    unique_classes, counts = np.unique(class_preds_updated[class_preds_updated >= 0], return_counts=True)\n",
        "    for cls, count in zip(unique_classes, counts):\n",
        "        class_name = CLASS_NAMES[cls] if cls < len(CLASS_NAMES) else f\"class_{cls}\"\n",
        "        print(f\"  {class_name}: {count:,} points\")\n",
        "\n",
        "\n",
        "display_combined_results(coord, instance_preds_full, class_preds_updated)"
      ],
      "metadata": {
        "id": "8l1biw5DNn8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scannet 200: searching for smaller objects and detail thats missed."
      ],
      "metadata": {
        "id": "NqFeDAVCQUGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Classes to exclude from ScanNet 200 that overlap from scannet 20\n",
        "EXCLUDE_CLASSES = [4, 5, 6, 7, 14, 16, 21, 23, 27, 35, 44, 46, 172] #There are overlapping classes from scannet 20 view results below and feel free to add any more classes\n",
        "\n",
        "def step4_scannet200_filtered(coord, color, normal, instance_preds_full, class_preds_updated,\n",
        "                              pred_scores, pred_classes, semantic_preds):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 4: SCANNET 200 FILTERED RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"Excluding classes: {EXCLUDE_CLASSES}\")\n",
        "\n",
        "    # Load ScanNet 200 model\n",
        "    print(\"\\nLoading ScanNet 200 model...\")\n",
        "    cfg = Config.fromfile(SCANNET200_CONFIG)\n",
        "    model = build_model(cfg.model).cuda()\n",
        "    model.eval()\n",
        "\n",
        "    checkpoint = torch.load(SCANNET200_CHECKPOINT, map_location='cuda')\n",
        "    weight = OrderedDict()\n",
        "    for key, value in checkpoint[\"state_dict\"].items():\n",
        "        if key.startswith(\"module.\"):\n",
        "            key = key[7:]\n",
        "        weight[key] = value\n",
        "    model.load_state_dict(weight, strict=True)\n",
        "\n",
        "    # Prepare data\n",
        "    data_dict = {\n",
        "        'coord': coord.copy(),\n",
        "        'color': color.copy(),\n",
        "        'normal': normal.copy(),\n",
        "        'segment': np.zeros(coord.shape[0], dtype=np.int32),\n",
        "        'instance': np.full(coord.shape[0], -1, dtype=np.int32),\n",
        "    }\n",
        "\n",
        "    # Apply transforms\n",
        "    transform_list = [\n",
        "        dict(type=\"CenterShift\", apply_z=True),\n",
        "        dict(type=\"Copy\", keys_dict={\n",
        "            \"coord\": \"origin_coord\",\n",
        "            \"segment\": \"origin_segment\",\n",
        "            \"instance\": \"origin_instance\",\n",
        "        }),\n",
        "        dict(type=\"GridSample\", grid_size=SCANNET200_GRID_SIZE, hash_type=\"fnv\",\n",
        "             mode=\"train\", return_grid_coord=True),\n",
        "        dict(type=\"CenterShift\", apply_z=False),\n",
        "        dict(type=\"NormalizeColor\"),\n",
        "        dict(type=\"InstanceParser\", segment_ignore_index=(-1,), instance_ignore_index=-1),\n",
        "    ]\n",
        "\n",
        "    transform = Compose(transform_list)\n",
        "    data_dict = transform(data_dict)\n",
        "\n",
        "    # Convert to tensors\n",
        "    for key in data_dict.keys():\n",
        "        if isinstance(data_dict[key], np.ndarray):\n",
        "            if key in ['segment', 'instance', 'grid_coord', 'origin_segment', 'origin_instance']:\n",
        "                data_dict[key] = torch.from_numpy(data_dict[key]).long()\n",
        "            elif key == 'bbox':\n",
        "                data_dict[key] = torch.from_numpy(data_dict[key]).long()\n",
        "            else:\n",
        "                data_dict[key] = torch.from_numpy(data_dict[key]).float()\n",
        "\n",
        "    for key in data_dict.keys():\n",
        "        if isinstance(data_dict[key], torch.Tensor):\n",
        "            data_dict[key] = data_dict[key].cuda()\n",
        "\n",
        "    # Create features\n",
        "    if all(k in data_dict for k in [\"coord\", \"color\", \"normal\"]):\n",
        "        feat = torch.cat([data_dict[\"coord\"], data_dict[\"color\"], data_dict[\"normal\"]], dim=1)\n",
        "        data_dict[\"feat\"] = feat\n",
        "\n",
        "    # Add batch info\n",
        "    if \"coord\" in data_dict:\n",
        "        data_dict[\"batch\"] = torch.zeros(len(data_dict[\"coord\"]), dtype=torch.long).cuda()\n",
        "        data_dict[\"offset\"] = torch.tensor([len(data_dict[\"coord\"])], dtype=torch.long).cuda()\n",
        "\n",
        "    if \"origin_coord\" in data_dict:\n",
        "        data_dict[\"origin_offset\"] = torch.tensor([len(data_dict[\"origin_coord\"])], dtype=torch.long).cuda()\n",
        "\n",
        "    # Run inference\n",
        "    print(\"Running ScanNet 200 inference...\")\n",
        "    with torch.no_grad():\n",
        "        output_dict = model(data_dict)\n",
        "\n",
        "    # Process outputs\n",
        "    pred_masks = output_dict['pred_masks']\n",
        "    pred_scores = output_dict['pred_scores']\n",
        "    pred_classes = output_dict['pred_classes']\n",
        "\n",
        "    print(f\"\\nFound {len(pred_scores)} predicted instances\")\n",
        "\n",
        "    # Map back if needed\n",
        "    if \"origin_coord\" in data_dict and pointops is not None:\n",
        "        reverse, _ = pointops.knn_query(\n",
        "            1, data_dict[\"coord\"].float(), data_dict[\"offset\"].int(),\n",
        "            data_dict[\"origin_coord\"].float(), data_dict[\"origin_offset\"].int(),\n",
        "        )\n",
        "        reverse = reverse.cpu().flatten().long()\n",
        "        pred_masks = pred_masks[:, reverse]\n",
        "\n",
        "    # Convert to numpy\n",
        "    pred_masks = pred_masks.cpu().numpy()\n",
        "    pred_scores = pred_scores.cpu().numpy()\n",
        "    pred_classes = pred_classes.cpu().numpy()\n",
        "\n",
        "    # Clean up model\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Create instance/class predictions for ScanNet 200 ONLY\n",
        "    instance_preds_s200 = np.full(len(coord), -1, dtype=np.int32)\n",
        "    class_preds_s200 = np.full(len(coord), -1, dtype=np.int32)\n",
        "\n",
        "    # Apply filtered ScanNet 200 predictions\n",
        "    applied_count = 0\n",
        "    class_counts = {}\n",
        "\n",
        "    for i in range(len(pred_scores)):\n",
        "        if pred_scores[i] < SCANNET200_CONFIDENCE_THRESHOLD:\n",
        "            continue\n",
        "\n",
        "        # Skip excluded classes\n",
        "        if pred_classes[i] in EXCLUDE_CLASSES:\n",
        "            continue\n",
        "\n",
        "        mask = pred_masks[i] > 0\n",
        "        if mask.sum() < 50:  # Min points\n",
        "            continue\n",
        "\n",
        "        # Apply this instance\n",
        "        instance_preds_s200[mask] = i\n",
        "        class_preds_s200[mask] = pred_classes[i]\n",
        "\n",
        "        applied_count += 1\n",
        "\n",
        "        # Count classes\n",
        "        cls = pred_classes[i]\n",
        "        if cls not in class_counts:\n",
        "            class_counts[cls] = 0\n",
        "        class_counts[cls] += 1\n",
        "\n",
        "    print(f\"\\nApplied {applied_count} instances (after filtering)\")\n",
        "    print(f\"Points classified: {(class_preds_s200 >= 0).sum():,}\")\n",
        "\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    for cls, count in sorted(class_counts.items()):\n",
        "        print(f\"  Class {cls}: {count} instances\")\n",
        "\n",
        "    # VISUALIZATION - Show ONLY ScanNet 200 filtered results\n",
        "    print(\"\\nVisualizing ScanNet 200 filtered results...\")\n",
        "\n",
        "    # Sample for visualization\n",
        "    total_points = len(coord)\n",
        "    viz_sample = min(VIZ_MAX_POINTS * 2, total_points)\n",
        "    if total_points > viz_sample:\n",
        "        sample_indices = np.random.choice(total_points, viz_sample, replace=False)\n",
        "    else:\n",
        "        sample_indices = np.arange(total_points)\n",
        "\n",
        "    traces = []\n",
        "\n",
        "    # Color by class\n",
        "    unique_classes = np.unique(class_preds_s200[class_preds_s200 >= 0])\n",
        "    colors = px.colors.qualitative.Plotly + px.colors.qualitative.Set3 + px.colors.qualitative.Pastel\n",
        "\n",
        "    print(f\"\\nVisualizing {len(unique_classes)} unique classes\")\n",
        "\n",
        "    for idx, cls in enumerate(unique_classes[:50]):  # Show up to 50 classes\n",
        "        class_mask = (class_preds_s200 == cls) & np.isin(np.arange(total_points), sample_indices)\n",
        "        points = np.where(class_mask)[0]\n",
        "\n",
        "        if len(points) > 0:\n",
        "            traces.append(go.Scatter3d(\n",
        "                x=coord[points, 0],\n",
        "                y=coord[points, 1],\n",
        "                z=coord[points, 2],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=2,\n",
        "                    color=colors[idx % len(colors)],\n",
        "                    opacity=0.8\n",
        "                ),\n",
        "                name=f\"Class {cls} ({(class_preds_s200 == cls).sum()} pts)\",\n",
        "                showlegend=True\n",
        "            ))\n",
        "\n",
        "    #Show unclassified (everything not detected by filtered ScanNet 200)\n",
        "    unclass_mask = (class_preds_s200 == -1) & np.isin(np.arange(total_points), sample_indices)\n",
        "    if unclass_mask.sum() > 0:\n",
        "        traces.append(go.Scatter3d(\n",
        "            x=coord[unclass_mask, 0],\n",
        "            y=coord[unclass_mask, 1],\n",
        "            z=coord[unclass_mask, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='lightgray', opacity=0.2),\n",
        "            name=f\"Not detected ({(class_preds_s200 == -1).sum()} pts)\",\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    # Create ploty figure\n",
        "    fig = go.Figure(data=traces)\n",
        "    fig.update_layout(\n",
        "        title=f\"ScanNet 200 Filtered: {applied_count} instances, {len(unique_classes)} classes (excluding: {EXCLUDE_CLASSES})\",\n",
        "        scene=dict(\n",
        "            xaxis_title='X',\n",
        "            yaxis_title='Y',\n",
        "            zaxis_title='Z',\n",
        "            aspectmode='data'\n",
        "        ),\n",
        "        width=1400,\n",
        "        height=900,\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.99,\n",
        "            xanchor=\"right\",\n",
        "            x=0.99,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "            font=dict(size=10)\n",
        "        )\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    print(\"\\nStep 4 complete\")\n",
        "    return instance_preds_s200, class_preds_s200, pred_scores, pred_classes\n",
        "\n",
        "instance_preds_s200, class_preds_s200, pred_scores_s200, pred_classes_s200 = step4_scannet200_filtered(\n",
        "    coord, color, normal, instance_preds_full, class_preds_updated,\n",
        "    pred_scores, pred_classes, semantic_preds\n",
        ")"
      ],
      "metadata": {
        "id": "8qPjDyaIPdPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   # Merge ScanNet 200 results with Steps 2-3 results."
      ],
      "metadata": {
        "id": "0t2U7EyQQfCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def step5_merge_and_display(coord, instance_preds_full, class_preds_updated,\n",
        "                          instance_preds_s200, class_preds_s200):\n",
        "\n",
        "   print(\"\\n\" + \"=\"*60)\n",
        "   print(\"MERGING RESULTS AND DISPLAYING\")\n",
        "   print(\"=\"*60)\n",
        "  # Merge predicions\n",
        "\n",
        "   # Load predictions from previous steps\n",
        "   instance_preds_final = instance_preds_full.copy()\n",
        "   class_preds_final = class_preds_updated.copy()\n",
        "\n",
        "\n",
        "   replaced_mask = (class_preds_s200 >= 0)  # Where ScanNet 200 has predictions\n",
        "   replaced_count = replaced_mask.sum()\n",
        "\n",
        "   #Get total number of exisiting instance ID from Steps 2-3\n",
        "   max_instance_id = instance_preds_full.max() if instance_preds_full.max() >= 0 else -1\n",
        "\n",
        "   #This is where we replace the predctions from scannet 200 over the previous predictions\n",
        "   for i in np.where(replaced_mask)[0]:\n",
        "       # Get ScanNet 200 instance and class\n",
        "       s200_instance = instance_preds_s200[i]\n",
        "       s200_class = class_preds_s200[i]\n",
        "\n",
        "       #Change instance ID's (offset to avoid conflicting numbers)\n",
        "       instance_preds_final[i] = s200_instance + max_instance_id + 1\n",
        "       class_preds_final[i] = s200_class\n",
        "\n",
        "   # Get final stats\n",
        "   total_points = len(coord)\n",
        "   classified_points = (class_preds_final >= 0).sum()\n",
        "   unclassified_points = (class_preds_final == -1).sum()\n",
        "\n",
        "   # Save final results\n",
        "   np.save(os.path.join(SCENE_PATH, 'instance_preds_final.npy'), instance_preds_final)\n",
        "   np.save(os.path.join(SCENE_PATH, 'class_preds_final.npy'), class_preds_final)\n",
        "\n",
        "   print(f\"Replaced {replaced_count:,} points with ScanNet 200 classifications\")\n",
        "   print(f\"\\nFinal statistics:\")\n",
        "   print(f\"Total points: {total_points:,}\")\n",
        "   print(f\"Classified points: {classified_points:,} ({classified_points/total_points*100:.1f}%)\")\n",
        "   print(f\"Unclassified points: {unclassified_points:,} ({unclassified_points/total_points*100:.1f}%)\")\n",
        "\n",
        "   traces = []\n",
        "\n",
        "   # Sample for visualization\n",
        "   viz_sample = min(VIZ_MAX_POINTS * 2, total_points)\n",
        "   if total_points > viz_sample:\n",
        "       sample_indices = np.random.choice(total_points, viz_sample, replace=False)\n",
        "   else:\n",
        "       sample_indices = np.arange(total_points)\n",
        "\n",
        "   # Get all unique instances and their classes\n",
        "   unique_instances = np.unique(instance_preds_final[instance_preds_final >= 0])\n",
        "\n",
        "   # Separate original and ScanNet 200 instances\n",
        "   original_instances = []\n",
        "   s200_instances = []\n",
        "\n",
        "   for inst_id in unique_instances:\n",
        "       mask = instance_preds_final == inst_id\n",
        "       if mask.sum() > 0:\n",
        "           class_id = class_preds_final[mask][0]\n",
        "           if class_id >= 2:  # Not wall or floor\n",
        "               if inst_id > max_instance_id:\n",
        "                   s200_instances.append((inst_id, class_id, mask.sum()))\n",
        "               else:\n",
        "                   original_instances.append((inst_id, class_id, mask.sum()))\n",
        "\n",
        "   # Sort by size\n",
        "   original_instances.sort(key=lambda x: x[2], reverse=True)\n",
        "   s200_instances.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "   print(f\"\\nOriginal instances (ScanNet 20): {len(original_instances)}\")\n",
        "   print(f\"ScanNet 200 instances: {len(s200_instances)}\")\n",
        "   print(f\"Points replaced by ScanNet 200: {replaced_count:,}\")\n",
        "\n",
        "   # Attempting to get more color variation\n",
        "   instance_colors = (\n",
        "       px.colors.qualitative.Plotly +\n",
        "       px.colors.qualitative.D3 +\n",
        "       px.colors.qualitative.G10 +\n",
        "       px.colors.qualitative.T10 +\n",
        "       px.colors.qualitative.Alphabet +\n",
        "       px.colors.qualitative.Dark24 +\n",
        "       px.colors.qualitative.Light24\n",
        "   )\n",
        "\n",
        "   # Walls (unchanged from Steps 2-3)\n",
        "   wall_mask = (class_preds_final == 0) & np.isin(np.arange(total_points), sample_indices)\n",
        "   wall_points = np.where(wall_mask)[0]\n",
        "   if len(wall_points) > 0:\n",
        "       traces.append(go.Scatter3d(\n",
        "           x=coord[wall_points, 0],\n",
        "           y=coord[wall_points, 1],\n",
        "           z=coord[wall_points, 2],\n",
        "           mode='markers',\n",
        "           marker=dict(size=1, color='lightblue', opacity=0.6),\n",
        "           name=f\"Walls ({(class_preds_final == 0).sum():,} pts)\",\n",
        "           showlegend=True\n",
        "       ))\n",
        "\n",
        "   #Floor classification (unchanged from Steps 2-3)\n",
        "   floor_mask = (class_preds_final == 1) & np.isin(np.arange(total_points), sample_indices)\n",
        "   floor_points = np.where(floor_mask)[0]\n",
        "   if len(floor_points) > 0:\n",
        "       traces.append(go.Scatter3d(\n",
        "           x=coord[floor_points, 0],\n",
        "           y=coord[floor_points, 1],\n",
        "           z=coord[floor_points, 2],\n",
        "           mode='markers',\n",
        "           marker=dict(size=1, color='lightgreen', opacity=0.6),\n",
        "           name=f\"Floors ({(class_preds_final == 1).sum():,} pts)\",\n",
        "           showlegend=True\n",
        "       ))\n",
        "\n",
        "   # Plot original instances\n",
        "   for idx, (inst_id, class_id, size) in enumerate(original_instances[:20]):\n",
        "       mask = (instance_preds_final == inst_id) & np.isin(np.arange(total_points), sample_indices)\n",
        "       indices = np.where(mask)[0]\n",
        "\n",
        "       if len(indices) > 0:\n",
        "           class_name = CLASS_NAMES[class_id] if 0 <= class_id < len(CLASS_NAMES) else f\"class_{class_id}\"\n",
        "\n",
        "           traces.append(go.Scatter3d(\n",
        "               x=coord[indices, 0],\n",
        "               y=coord[indices, 1],\n",
        "               z=coord[indices, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(\n",
        "                   size=2,\n",
        "                   color=instance_colors[idx % len(instance_colors)],\n",
        "                   opacity=0.9\n",
        "               ),\n",
        "               name=f\"{class_name} #{inst_id} ({size:,} pts)\",\n",
        "               showlegend=True\n",
        "           ))\n",
        "\n",
        "   # Plot ScanNet 200 instances\n",
        "   for idx, (inst_id, class_id, size) in enumerate(s200_instances[:20]):\n",
        "       mask = (instance_preds_final == inst_id) & np.isin(np.arange(total_points), sample_indices)\n",
        "       indices = np.where(mask)[0]\n",
        "\n",
        "       if len(indices) > 0:\n",
        "           traces.append(go.Scatter3d(\n",
        "               x=coord[indices, 0],\n",
        "               y=coord[indices, 1],\n",
        "               z=coord[indices, 2],\n",
        "               mode='markers',\n",
        "               marker=dict(\n",
        "                   size=2,\n",
        "                   color=instance_colors[(len(original_instances) + idx) % len(instance_colors)],\n",
        "                   opacity=0.9\n",
        "               ),\n",
        "               name=f\"S200: Class {class_id} ({size:,} pts)\",\n",
        "               showlegend=True\n",
        "           ))\n",
        "\n",
        "   #Unclassified points\n",
        "   unclass_mask = (class_preds_final == -1) & np.isin(np.arange(total_points), sample_indices)\n",
        "   unclass_points = np.where(unclass_mask)[0]\n",
        "   if len(unclass_points) > 0:\n",
        "       traces.append(go.Scatter3d(\n",
        "           x=coord[unclass_points, 0],\n",
        "           y=coord[unclass_points, 1],\n",
        "           z=coord[unclass_points, 2],\n",
        "           mode='markers',\n",
        "           marker=dict(size=1, color='gray', opacity=0.3),\n",
        "           name=f\"Unclassified ({unclassified_points:,} pts)\",\n",
        "           showlegend=True\n",
        "       ))\n",
        "\n",
        "   #Create figure\n",
        "   fig = go.Figure(data=traces)\n",
        "   fig.update_layout(\n",
        "       title=f\"Final Merged Results: {len(original_instances)} ScanNet 20 + {len(s200_instances)} ScanNet 200 instances\",\n",
        "       scene=dict(\n",
        "           xaxis_title='X',\n",
        "           yaxis_title='Y',\n",
        "           zaxis_title='Z',\n",
        "           aspectmode='data'\n",
        "       ),\n",
        "       width=1400,\n",
        "       height=900,\n",
        "       showlegend=True,\n",
        "       legend=dict(\n",
        "           yanchor=\"top\",\n",
        "           y=0.99,\n",
        "           xanchor=\"right\",\n",
        "           x=0.99,\n",
        "           bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "           font=dict(size=10)\n",
        "       )\n",
        "   )\n",
        "   fig.show()\n",
        "\n",
        "   print(\"Results are Merged\")\n",
        "   return instance_preds_final, class_preds_final\n",
        "\n",
        "\n",
        "instance_preds_final, class_preds_final = step5_merge_and_display(\n",
        "   coord, instance_preds_full, class_preds_updated,\n",
        "   instance_preds_s200, class_preds_s200\n",
        ")"
      ],
      "metadata": {
        "id": "TagWY0-NQLwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reload the orginal unmodified PLY file and assign classifications and export out a new ply file"
      ],
      "metadata": {
        "id": "7p-egGBrRHTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def step6_export_ply_final(coord, instance_preds_final, class_preds_final,\n",
        "                          instance_preds_s200, class_preds_s200):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPORTING PLY WITH SCANNET 20 AND 200 ATTRIBUTES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    #Loading the ORIGINAL PLY file - NOT the converted numpy arrays\n",
        "    print(f\"Loading ORIGINAL PLY file: {PLY_PATH}\")\n",
        "    plydata = PlyData.read(PLY_PATH)\n",
        "    vertex_data = plydata['vertex']\n",
        "    original_point_count = len(vertex_data)\n",
        "    print(f\"Original PLY has {original_point_count:,} points\")\n",
        "\n",
        "    #Verify array sizes match between both the classes and\n",
        "    assert len(instance_preds_final) == original_point_count, f\"Instance predictions size mismatch\"\n",
        "    assert len(class_preds_final) == original_point_count, f\"Class predictions size mismatch\"\n",
        "\n",
        "    # Prepare ScanNet 20 and ScanNet 200 attributes\n",
        "    scannet20_class = np.full(original_point_count, -1, dtype=np.int32)\n",
        "    scannet20_instance = np.full(original_point_count, -1, dtype=np.int32)\n",
        "    scannet200_class = np.full(original_point_count, -1, dtype=np.int32)\n",
        "    scannet200_instance = np.full(original_point_count, -1, dtype=np.int32)\n",
        "\n",
        "\n",
        "    for i in range(original_point_count):\n",
        "        #Check if this point has a ScanNet 200 classification\n",
        "        if class_preds_s200[i] >= 0:\n",
        "            # This is a ScanNet 200 point\n",
        "            if class_preds_s200[i] == 2:  # Floor in S200\n",
        "                scannet20_class[i] = 1  # Floor in S20\n",
        "                scannet20_instance[i] = instance_preds_final[i]\n",
        "            else:\n",
        "                # If not a floor give it a S200 attribute\n",
        "                scannet200_class[i] = class_preds_s200[i]\n",
        "                scannet200_instance[i] = instance_preds_s200[i]\n",
        "        else:\n",
        "            # This is a ScanNet 20 points not touched (from steps 2-3)\n",
        "            if class_preds_final[i] >= 0:\n",
        "                scannet20_class[i] = class_preds_final[i]\n",
        "                scannet20_instance[i] = instance_preds_final[i]\n",
        "\n",
        "    # Print statistics\n",
        "    s20_count = (scannet20_class >= 0).sum()\n",
        "    s200_count = (scannet200_class >= 0).sum()\n",
        "    unclassified = original_point_count - s20_count - s200_count\n",
        "\n",
        "    print(f\"\\nClassification summary:\")\n",
        "    print(f\"  ScanNet 20 points: {s20_count:,} ({s20_count/original_point_count*100:.1f}%)\")\n",
        "    print(f\"  ScanNet 200 points: {s200_count:,} ({s200_count/original_point_count*100:.1f}%)\")\n",
        "    print(f\"  Unclassified: {unclassified:,} ({unclassified/original_point_count*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\nPreparing new PLY structure...\")\n",
        "    original_dtype = vertex_data.data.dtype\n",
        "    new_dtype_list = [(name, original_dtype[name]) for name in original_dtype.names]\n",
        "\n",
        "    # Add our segmentation attributes\n",
        "    new_dtype_list.append(('scannet20_class', 'i4'))      # ScanNet 20 class ID (-1 if none)\n",
        "    new_dtype_list.append(('scannet20_instance', 'i4'))   # ScanNet 20 instance ID (-1 if none)\n",
        "    new_dtype_list.append(('scannet200_class', 'i4'))     # ScanNet 200 class ID (-1 if none)\n",
        "    new_dtype_list.append(('scannet200_instance', 'i4'))  # ScanNet 200 instance ID (-1 if none)\n",
        "\n",
        "    #Create new vertex array\n",
        "    new_vertex = np.zeros(original_point_count, dtype=new_dtype_list)\n",
        "\n",
        "    #Copy ALL original data (including spherical harmonics)\n",
        "    print(\"Copying ALL original vertex properties...\")\n",
        "    spherical_harmonic_count = 0\n",
        "    for prop in original_dtype.names:\n",
        "        new_vertex[prop] = vertex_data[prop]\n",
        "        if 'f_dc' in prop or 'f_rest' in prop:\n",
        "            spherical_harmonic_count += 1\n",
        "\n",
        "\n",
        "    print(f\"  Total properties preserved: {len(original_dtype.names)} (including {spherical_harmonic_count} SH coefficients)\")\n",
        "\n",
        "    #Add segementation Attributes\n",
        "    print(\"\\nAdding segmentation attributes...\")\n",
        "    new_vertex['scannet20_class'] = scannet20_class\n",
        "    new_vertex['scannet20_instance'] = scannet20_instance\n",
        "    new_vertex['scannet200_class'] = scannet200_class\n",
        "    new_vertex['scannet200_instance'] = scannet200_instance\n",
        "\n",
        "    #Output path\n",
        "    output_dir = '/content/drive/MyDrive/Pointcept/output'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_filename = f'{SCENE_NAME}_segmented_s20_s200.ply'\n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "    # Save PLY in same format as original\n",
        "    print(f\"\\nSaving Classified PLY to: {output_path}\")\n",
        "\n",
        "    # Check original format\n",
        "    original_format_is_text = plydata.text\n",
        "    print(f\"Original PLY format: {'text' if original_format_is_text else 'binary'}\")\n",
        "\n",
        "    # Create element and save in same format\n",
        "    el = PlyElement.describe(new_vertex, 'vertex')\n",
        "    PlyData([el], text=original_format_is_text).write(output_path)\n",
        "\n",
        "    # Verify file size\n",
        "    file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
        "    print(f\"Output file size: {file_size:.2f} MB\")\n",
        "\n",
        "\n",
        "    # ScanNet 20 class distribution\n",
        "    print(\"\\nScanNet 20 Classes:\")\n",
        "    unique_s20, counts_s20 = np.unique(scannet20_class[scannet20_class >= 0], return_counts=True)\n",
        "    for cls, count in zip(unique_s20, counts_s20):\n",
        "        class_name = CLASS_NAMES[cls] if cls < len(CLASS_NAMES) else f\"class_{cls}\"\n",
        "        print(f\"  {class_name} (class {cls}): {count:,} points\")\n",
        "\n",
        "    # ScanNet 200 class distribution\n",
        "    print(\"\\nScanNet 200 Classes:\")\n",
        "    unique_s200, counts_s200 = np.unique(scannet200_class[scannet200_class >= 0], return_counts=True)\n",
        "    for cls, count in zip(unique_s200, counts_s200):\n",
        "        print(f\"  Class {cls}: {count:,} points\")\n",
        "\n",
        "    # Instance counts\n",
        "    s20_instances = len(np.unique(scannet20_instance[scannet20_instance >= 0]))\n",
        "    s200_instances = len(np.unique(scannet200_instance[scannet200_instance >= 0]))\n",
        "    print(f\"\\nInstance counts:\")\n",
        "    print(f\"  ScanNet 20 instances: {s20_instances}\")\n",
        "    print(f\"  ScanNet 200 instances: {s200_instances}\")\n",
        "\n",
        "    # Create summary JSON\n",
        "    summary = {\n",
        "        'filename': output_filename,\n",
        "        'original_ply': PLY_PATH,\n",
        "        'export_timestamp': pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'total_points': int(original_point_count),\n",
        "        'segmentation_stats': {\n",
        "            'scannet20_points': int(s20_count),\n",
        "            'scannet200_points': int(s200_count),\n",
        "            'unclassified_points': int(unclassified),\n",
        "            'scannet20_instances': int(s20_instances),\n",
        "            'scannet200_instances': int(s200_instances)\n",
        "        },\n",
        "        'scannet20_classes': {\n",
        "            (CLASS_NAMES[cls] if cls < len(CLASS_NAMES) else f'class_{cls}'): int(count)\n",
        "            for cls, count in zip(unique_s20, counts_s20)\n",
        "        },\n",
        "        'scannet200_classes': {\n",
        "            f'class_{cls}': int(count)\n",
        "            for cls, count in zip(unique_s200, counts_s200)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save summary JSON file\n",
        "    summary_path = output_path.replace('.ply', '_summary.json')\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    print(f\"\\nSaved summary to: {summary_path}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PLY EXPORT COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nOutput file: {output_path}\")\n",
        "\n",
        "     # Print Houdini group expressions\n",
        "\n",
        "    # Get unique ScanNet 20 instances (excluding -1)\n",
        "    s20_unique_instances = np.unique(scannet20_instance[scannet20_instance >= 0])\n",
        "    print(f\"\\nScanNet 20 - All {len(s20_unique_instances)} instance IDs:\")\n",
        "    for instance_id in sorted(s20_unique_instances):\n",
        "        print(f\"  {instance_id}\")\n",
        "\n",
        "    # Get unique ScanNet 200 instances (excluding -1)\n",
        "    s200_unique_instances = np.unique(scannet200_instance[scannet200_instance >= 0])\n",
        "    print(f\"\\nScanNet 200 - All {len(s200_unique_instances)} instance IDs:\")\n",
        "    for instance_id in sorted(s200_unique_instances):\n",
        "        print(f\"  {instance_id}\")\n",
        "\n",
        "    # Print Houdini group expressions\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Houdini VEX EXPRESSIONS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nTo select all unclassified points:\")\n",
        "    print(\"  @scannet20_instance==-1 @scannet200_instance==-1\")\n",
        "\n",
        "    print(\"\\nTo select each ScanNet 20 instance:\")\n",
        "    for instance_id in sorted(s20_unique_instances):\n",
        "        print(f\"  @scannet20_instance=={instance_id}\")\n",
        "\n",
        "    print(\"\\nTo select each ScanNet 200 instance:\")\n",
        "    for instance_id in sorted(s200_unique_instances):\n",
        "        print(f\"  @scannet200_instance=={instance_id}\")\n",
        "\n",
        "\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "output_path = step6_export_ply_final(\n",
        "    coord, instance_preds_final, class_preds_final,\n",
        "    instance_preds_s200, class_preds_s200\n",
        ")"
      ],
      "metadata": {
        "id": "YR50Y6TmQ2-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the following to see the scannet 20 and scannet 200 classes optional\n",
        "for i, class_name in enumerate(CLASS_NAMES):\n",
        "    print(f\"{i}: {class_name}\")\n",
        "\n",
        "from pointcept.datasets.preprocessing.scannet.meta_data.scannet200_constants import CLASS_LABELS_200\n",
        "\n",
        "# Print all 200 class names\n",
        "for i, class_name in enumerate(CLASS_LABELS_200):\n",
        "    print(f\"{i}: {class_name}\")"
      ],
      "metadata": {
        "id": "VvLR-MHGpKoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}